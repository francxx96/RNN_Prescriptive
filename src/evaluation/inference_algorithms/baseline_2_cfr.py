"""
this file is built based on the code found in evaluate_suffix_and_remaining_time.py
here the beam search (with breath-first-search) is implemented, to find compliant prediction
The code is expanded to also consider the Resource attribute
"""

from __future__ import division
import csv
from pathlib import Path
import time
from queue import PriorityQueue
import distance
import numpy as np
from tensorflow.keras.models import load_model
from jellyfish import damerau_levenshtein_distance

from src.commons import utils, shared_variables as shared
from src.evaluation.prepare_data import get_symbol_ampl, encode_with_group, prepare_testing_data, get_group_symbol, \
    select_petrinet_verified_traces, amplify, get_pn_fitness


def run_experiments(log_name, models_folder, fold):
    pn_model_filename = utils.extract_petrinet_filename(log_name)
    start_time = time.time()

    # prepare the data
    lines, lines_id, lines_group, lines_o, maxlen, chars, chars_group, char_indices, char_indices_group, predict_size, \
        target_indices_char, target_indices_char_group, target_char_indices, target_char_indices_group \
        = prepare_testing_data(log_name)

    # find cycles and modify the probability functionality goes here
    stop_symbol_probability_amplifier_current = 1

    # load model, set this to the model generated by train.py
    model_filename = utils.extract_last_model_checkpoint(log_name, models_folder, fold, 'CFR')
    model = load_model(model_filename)

    class NodePrediction:
        def __init__(self, data, trace_id, crop_line, crop_line_group, outcome, probability_of=0):
            self.data = data
            self.trace_id = trace_id
            self.cropped_line = crop_line
            self.cropped_line_group = crop_line_group
            self.outcome = outcome
            self.probability_of = probability_of

        def __lt__(self, other):
            return -self.probability_of < -other.probability_of

    folder_path = shared.output_folder / models_folder / str(fold) / 'results' / 'baseline2'
    if not Path.exists(folder_path):
        Path.mkdir(folder_path, parents=True)
    output_filename = folder_path / (log_name + '_CFR.csv')

    with open(output_filename, 'w') as csvfile:
        spamwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)
        # headers for the new file
        spamwriter.writerow(["Prefix length", "Ground truth", "Predicted", "Damerau-Levenshtein", "Jaccard",
                             "Ground Truth Group", "Predicted Group", "Damerau-Levenshtein Resource",
                             "Ground truth outcome", "Predicted outcome", "Outcome diff.",
                             "compliantness"])

        curr_time = time.time()

        lines_s, lines_id_s, lines_group_s, lines_o_s \
            = select_petrinet_verified_traces(lines, lines_id, lines_group, lines_o, pn_model_filename)

        print("formulas verified: " + str(len(lines_s)) + " out of : " + str(len(lines)))
        print('elapsed_time:', time.time() - curr_time)

        # make predictions for different prefix sizes as specified in 'shared_variables'
        log_settings_dictionary = shared.log_settings[log_name]
        prefix_size_pred_from = log_settings_dictionary['prefix_size_pred_range'][0]
        prefix_size_pred_to = log_settings_dictionary['prefix_size_pred_range'][1]

        for prefix_size in range(prefix_size_pred_from, prefix_size_pred_to):
            print("prefix size: " + str(prefix_size))

            for line, line_id, line_group, line_outcome in zip(lines_s, lines_id_s, lines_group_s, lines_o_s):
                if len(line) < prefix_size:
                    continue  # make no prediction for this case, since this case has ended already

                cropped_line = ''.join(line[: prefix_size])
                cropped_line_group = ''.join(line_group[: prefix_size])

                ground_truth = ''.join(line[prefix_size: prefix_size+predict_size])
                ground_truth_group = ''.join(line_group[prefix_size: prefix_size+predict_size])
                ground_truth_o = line_outcome

                # initialize queue for beam search, put root of the tree inside
                queue_next_steps = PriorityQueue()
                queue_next_steps.put(
                    NodePrediction(
                        encode_with_group(cropped_line, cropped_line_group, maxlen, chars, chars_group, char_indices,
                                          char_indices_group),
                        line_id, cropped_line, cropped_line_group, ground_truth_o
                    )
                )

                queue_next_steps_future = PriorityQueue()
                start_of_the_cycle_symbol = " "
                found_satisfying_constraint = False

                current_beam_size = shared.beam_size
                current_prediction_premis = None

                for i in range(predict_size):
                    for k in range(current_beam_size):
                        if queue_next_steps.empty():
                            break

                        # _, current_prediction_premis = queue_next_steps.get()
                        current_prediction_premis = queue_next_steps.get()

                        if not found_satisfying_constraint:
                            if get_pn_fitness(pn_model_filename, line_id, current_prediction_premis.cropped_line,
                                              current_prediction_premis.cropped_line_group) >= shared.fitness_threshold:
                                # the formula verified and we can just finish the predictions
                                # beam size is 1 because predict only sequence of events
                                current_beam_size = 1
                                current_prediction_premis.probability_of = 0.0
                                # overwrite new queue
                                queue_next_steps_future = PriorityQueue()
                                found_satisfying_constraint = True

                        enc = current_prediction_premis.data
                        temp_cropped_line = current_prediction_premis.cropped_line
                        temp_cropped_line_group = current_prediction_premis.cropped_line_group
                        y = model.predict(enc, verbose=0)  # make predictions
                        # split predictions into seperate activity and time predictions
                        y_char = y[0][0]
                        y_group = y[1][0]
                        y_o = y[2][0][0]
                        predicted_outcome = '1' if y_o >= 0.5 else '0'

                        if not i == 0:
                            stop_symbol_probability_amplifier_current, start_of_the_cycle_symbol = \
                                amplify(temp_cropped_line)

                        for j in range(current_beam_size):
                            temp_prediction = get_symbol_ampl(y_char, target_indices_char, target_char_indices,
                                                              start_of_the_cycle_symbol,
                                                              stop_symbol_probability_amplifier_current, j)

                            temp_prediction_group = get_group_symbol(y_group, target_indices_char_group)

                            # end of case was just predicted, therefore, stop predicting further into the future
                            if temp_prediction == '!':
                                if get_pn_fitness(pn_model_filename, line_id, temp_cropped_line,
                                                  temp_cropped_line_group) >= shared.fitness_threshold:
                                    stop_symbol_probability_amplifier_current = 1
                                    # print('! predicted, end case')
                                    queue_next_steps = PriorityQueue()
                                    break
                                else:
                                    continue

                            temp_cropped_line = current_prediction_premis.cropped_line + temp_prediction
                            temp_cropped_line_group = current_prediction_premis.cropped_line_group + temp_prediction_group

                            temp_state_data = encode_with_group(temp_cropped_line, temp_cropped_line_group, maxlen,
                                                                chars, chars_group, char_indices, char_indices_group)
                            probability_this = np.sort(y_char)[len(y_char) - 1 - j]

                            temp = NodePrediction(temp_state_data, line_id, temp_cropped_line, temp_cropped_line_group,
                                                  predicted_outcome,
                                                  current_prediction_premis.probability_of + np.log(probability_this))

                            # queue_next_steps_future.put((-temp.probability_of, temp))
                            queue_next_steps_future.put(temp)
                            # print 'INFORMATION: ' + str(counterr) + ' ' + str(i) + ' ' + str(k) + ' ' + str(j) + ' ' + \
                            #       temp_cropped_line[prefix_size:] + "     " + str(temp.probability_of)

                    queue_next_steps = queue_next_steps_future
                    queue_next_steps_future = PriorityQueue()

                if current_prediction_premis is None:
                    print("Cannot find any trace that is compliant with formula given current beam size")
                    break

                predicted = (current_prediction_premis.cropped_line[prefix_size:])
                predicted_group = (current_prediction_premis.cropped_line_group[prefix_size:])
                predicted_outcome = current_prediction_premis.outcome

                compliantness = get_pn_fitness(pn_model_filename, line_id, current_prediction_premis.cropped_line,
                                               current_prediction_premis.cropped_line_group) >= 1

                output = []
                if len(ground_truth) > 0:
                    output.append(prefix_size)
                    output.append(ground_truth)
                    output.append(predicted)
                    # output.append(1 - distance.nlevenshtein(predicted, ground_truth))
                    dls = 1 - \
                        (damerau_levenshtein_distance(predicted, ground_truth) / max(len(predicted), len(ground_truth)))
                    if dls < 0:
                        dls = 0
                    output.append(dls)
                    output.append(1 - distance.jaccard(predicted, ground_truth))

                    output.append(ground_truth_group)
                    output.append(predicted_group)
                    # output.append(1 - distance.nlevenshtein(predicted_group, ground_truth_group))
                    dls_res = 1 - \
                        (damerau_levenshtein_distance(predicted_group, ground_truth_group)
                         / max(len(predicted_group), len(ground_truth_group)))
                    if dls_res < 0:
                        dls_res = 0
                    output.append(dls_res)

                    output.append(ground_truth_o)
                    output.append(predicted_outcome)
                    output.append('1' if ground_truth_o == predicted_outcome else '0')

                    output.append('1' if compliantness else '0')

                    spamwriter.writerow(output)

    print("TIME TO FINISH --- %s seconds ---" % (time.time() - start_time))
