"""
this script takes as input the LSTM or RNN weights found by train.py
change the path in the shared_variables.py to point to the h5 file
with LSTM or RNN weights generated by train.py

The script is expanded to also use the Resource attribute
"""

from __future__ import division

import csv
from pathlib import Path
import time
from jellyfish import damerau_levenshtein_distance
import distance
from tensorflow.keras.models import load_model
import shared_variables
from evaluation.prepare_data import select_petrinet_verified_traces, prepare_testing_data, encode_with_group, \
    get_symbol, get_group_symbol


def run_experiments(log_name, models_folder, fold):
    start_time = time.time()

    # prepare the data N.B. maxlen == predict_size
    lines, lines_id, lines_group, lines_o, maxlen, chars, chars_group, char_indices, char_indices_group, predict_size, \
        target_indices_char, target_indices_char_group, target_char_indices, target_char_indices_group = \
        prepare_testing_data(log_name)

    # load model, set this to the model generated by train.py
    model_filename = shared_variables.extract_last_model_checkpoint(log_name, models_folder, fold, 'CFR')
    model = load_model(model_filename)

    folder_path = shared_variables.outputs_folder / models_folder / str(fold) / 'results' / 'baseline1'
    if not Path.exists(folder_path):
        Path.mkdir(folder_path, parents=True)
    output_filename = folder_path / (log_name + '_CFR.csv')

    with open(output_filename, 'w') as csvfile:
        spamwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)
        spamwriter.writerow(["Prefix length", "Ground truth", "Predicted", "Damerau-Levenshtein", "Jaccard",
                             "Ground Truth Group", "Predicted Group", "Damerau-Levenshtein Resource",
                             "Ground truth outcome", "Predicted outcome", "Outcome diff."])

        curr_time = time.time()

        pn_model_filename = shared_variables.extract_petrinet_filename(log_name)
        lines_s, lines_id_s, lines_group_s, lines_o_s \
            = select_petrinet_verified_traces(lines, lines_id, lines_group, lines_o, pn_model_filename)

        print("formulas verified: " + str(len(lines_s)) + " out of : " + str(len(lines)))
        print('elapsed_time:', time.time() - curr_time)

        log_settings_dictionary = shared_variables.log_settings[log_name]
        prefix_size_pred_from = log_settings_dictionary['prefix_size_pred_from']
        prefix_size_pred_to = log_settings_dictionary['prefix_size_pred_to']

        for prefix_size in range(prefix_size_pred_from, prefix_size_pred_to):
            print("prefix size: " + str(prefix_size))
            for line, line_id, line_group, outcome in zip(lines_s, lines_id_s, lines_group_s, lines_o_s):

                if len(line) < prefix_size:
                    continue  # make no prediction for this case, since this case has ended already

                cropped_line = ''.join(line[: prefix_size])
                cropped_line_group = ''.join(line_group[: prefix_size])

                ground_truth = ''.join(line[prefix_size: prefix_size+predict_size])
                ground_truth_group = ''.join(line_group[prefix_size: prefix_size+predict_size])
                ground_truth_o = outcome

                predicted = ''
                predicted_group = ''

                for i in range(predict_size):
                    enc = encode_with_group(cropped_line, cropped_line_group, maxlen, chars, chars_group, char_indices,
                                            char_indices_group)
                    y = model.predict(enc, verbose=0)  # make predictions
                    # split predictions into separate activity and time predictions
                    y_char = y[0][0]
                    y_group = y[1][0]
                    y_o = y[2][0][0]

                    prediction = get_symbol(y_char)  # undo one-hot encoding
                    prediction_group = get_group_symbol(y_group, target_indices_char_group)  # undo one-hot encoding

                    if prediction == '!':
                        # end of case was just predicted, therefore, stop predicting further into the future
                        break

                    cropped_line += prediction
                    cropped_line_group += prediction_group
                    predicted += prediction
                    predicted_group += prediction_group
                    predicted_outcome = '1' if y_o >= 0.5 else '0'

                output = []
                if len(ground_truth) > 0:
                    output.append(prefix_size)
                    output.append(ground_truth)
                    output.append(predicted)
                    # output.append(1 - distance.nlevenshtein(predicted, ground_truth))
                    dls = 1 - \
                        (damerau_levenshtein_distance(predicted, ground_truth) / max(len(predicted), len(ground_truth)))
                    if dls < 0:
                        dls = 0
                    output.append(dls)
                    output.append(1 - distance.jaccard(predicted, ground_truth))

                    output.append(ground_truth_group)
                    output.append(predicted_group)
                    # output.append(1 - distance.nlevenshtein(predicted_group, ground_truth_group))
                    dls_res = 1 - \
                        (damerau_levenshtein_distance(predicted_group, ground_truth_group)
                         / max(len(predicted_group), len(ground_truth_group)))
                    if dls_res < 0:
                        dls_res = 0
                    output.append(dls_res)

                    output.append(ground_truth_o)
                    output.append(predicted_outcome)
                    output.append('1' if ground_truth_o == predicted_outcome else '0')

                    spamwriter.writerow(output)
    print("TIME TO FINISH --- %s seconds ---" % (time.time() - start_time))
